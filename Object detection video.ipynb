{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "03983660",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'    # Suppress TensorFlow logging (1)\n",
    "import pathlib\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys  \n",
    "df_zone = pd.read_csv('file1.csv')\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')           # Suppress TensorFlow logging (2)\n",
    "\n",
    "# Enable GPU dynamic memory allocation\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "def download_images():\n",
    "#     base_url = 'https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/test_images/'\n",
    "#     filenames = ['image1.jpg', 'image2.jpg']\n",
    "    base_url = 'workspace/training_demo/images/train/'\n",
    "    \n",
    "    filenames = []\n",
    "    for root, directories, file in os.walk(base_url):\n",
    "        for i in range(120, 300):\n",
    "            if(file[i].endswith(\".jpg\")):\n",
    "                print(os.path.join(file[i]))\n",
    "                filenames.append(os.path.join(file[i]))\n",
    "#     filenames = ['evraz 120.jpg', 'evraz 250.jpg']\n",
    "    image_paths = []\n",
    "    for filename in filenames:\n",
    "#         image_path = tf.keras.utils.get_file(fname=filename,\n",
    "#                                             origin=base_url + filename,\n",
    "#                                             untar=False)\n",
    "        image_path = base_url + filename\n",
    "        image_path = pathlib.Path(image_path)\n",
    "        image_paths.append(str(image_path))\n",
    "    return image_paths\n",
    "\n",
    "IMAGE_PATHS = download_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2e5c5d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Download and extract model\n",
    "# def download_model(model_name, model_date):\n",
    "#     base_url = 'http://download.tensorflow.org/models/object_detection/tf2/'\n",
    "#     model_file = model_name + '.tar.gz'\n",
    "#     model_dir = tf.keras.utils.get_file(fname=model_name,\n",
    "#                                         origin=base_url + model_date + '/' + model_file,\n",
    "#                                         untar=True)\n",
    "#     return str(model_dir)\n",
    "\n",
    "# MODEL_DATE = '20200711'\n",
    "# MODEL_NAME = 'covsh_net-32'\n",
    "# PATH_TO_MODEL_DIR = download_model(MODEL_NAME, MODEL_DATE)\n",
    "PATH_TO_MODEL_DIR = r'workspace/training_demo/exported-models/my_model/'\n",
    "PATH_TO_PEOPLE_MODEL = r'workspace\\training_demo\\pre-trained-models\\ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/saved_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f2af354d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Download labels file\n",
    "# def download_labels(filename):\n",
    "#     base_url = 'https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/data/'\n",
    "#     label_dir = tf.keras.utils.get_file(fname=filename,\n",
    "#                                         origin=base_url + filename,\n",
    "#                                         untar=False)\n",
    "#     label_dir = pathlib.Path(label_dir)\n",
    "#     return str(label_dir)\n",
    "\n",
    "PATH_TO_LABELS = 'workspace/training_demo/annotations/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "81c051db",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_FILENAME = 'label_map.pbtxt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "71bfa115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...Done! Took 35.278002977371216 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "\n",
    "PATH_TO_SAVED_MODEL = PATH_TO_MODEL_DIR + \"saved_model\"\n",
    "\n",
    "print('Loading model...', end='')\n",
    "start_time = time.time()\n",
    "\n",
    "# Load saved model and build the detection function\n",
    "detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)\n",
    "\n",
    "detect_people = tf.saved_model.load(PATH_TO_PEOPLE_MODEL)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print('Done! Took {} seconds'.format(elapsed_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cfa21622",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_index = {1:{'id': 1, 'name': 'Dangerous0'}, 2:{'id': 2, 'name': 'Dangerous1'}, 3:{'id': 3, 'name': 'Fastening0'}, 4:{'id': 4, 'name': 'Fastening1'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "14e793f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_index_people = {1:{'id': 1, 'name': '/m/01g317', 'display_name': 'people'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f5cc775a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_VIDEO = \"C:/Tensorflow/video/2021-12-03 07-07-48.avi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "913fb726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findDistance(line, x_center_line, y_center_line):\n",
    "    x1, y1, x2, y2 = line\n",
    "    under_line = x2 - x1 if x2 > x1 else x1 - x2\n",
    "    small_under_line = x2 - x_center_line if y2 > y1 else x_center_line - x1\n",
    "    vertial_line = y1 - y2 if y1 > y2 else y2 - y1\n",
    "    y_lowest = y1 if y1 < y2 else y2\n",
    "    height = under_line * vertial_line / small_under_line\n",
    "    y_peresek_line = y_lowest + height\n",
    "    return y_peresek_line - y_center_line\n",
    "\n",
    "\n",
    "def findNearestLine(df, x_center_line, y_center_line):\n",
    "    nearest_index = 0\n",
    "    min_distance = sys.maxsize\n",
    "    for i in range(len(df)):\n",
    "        lh_x, lh_y, rh_x, rh_y, ld_x, ld_y = df.iloc[i, 1], df.iloc[i, 2], df.iloc[i, 3], df.iloc[i, 4], df.iloc[i, 5], df.iloc[i, 6]\n",
    "        line1 = [lh_x, lh_y, rh_x, rh_y]\n",
    "        line2 = [ld_x, ld_y, lh_x, lh_y]\n",
    "        lines = [line1, line2]\n",
    "        for line in lines:\n",
    "            if line[0] < x_center_line < line[2]:\n",
    "                cur_dist = findDistance(line, x_center_line, y_center_line)\n",
    "                if cur_dist < min_distance:\n",
    "                    nearest_index = i\n",
    "                    min_distance = cur_dist\n",
    "\n",
    "    return nearest_index\n",
    "\n",
    "\n",
    "def zoneDrawer(df, img, i):\n",
    "#     for i in range(len(df)):\n",
    "    mas = np.array([[df['lh_x'][i], df['lh_y'][i]], [df['rh_x'][i], df['rh_y'][i]], [df['rd_x'][i], df['rd_y'][i]], [df['ld_x'][i], df['ld_y'][i]]], np.int32)\n",
    "    mas = mas.reshape((-1, 1, 2))\n",
    "    image = cv2.polylines(img, [mas], True, (0, 0, 255), 4)\n",
    "    return image\n",
    "\n",
    "\n",
    "# img = cv2.imread(r'evraz 432.jpg')\n",
    "x_y = []\n",
    "def on_EVENT_LBUTTONDOWN(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        x_y.append(x)\n",
    "        x_y.append(y)\n",
    "        xy = \"%d,%d\" % (x, y)\n",
    "        cv2.circle(img, (x, y), 1, (255, 0, 0), thickness = -1)\n",
    "        cv2.putText(img, xy, (x, y), cv2.FONT_HERSHEY_PLAIN,\n",
    "                    1.0, (0,0,0), thickness = 1)\n",
    "        cv2.imshow(\"image\", img)\n",
    "        print(x_y)\n",
    "# cv2.namedWindow(\"image\")\n",
    "# cv2.setMouseCallback(\"image\", on_EVENT_LBUTTONDOWN)\n",
    "\n",
    "# # i = 0\n",
    "\n",
    "\n",
    "# while (1):\n",
    "#     cv2.imshow('image', image)\n",
    "#     if cv2.waitKey(20) & 0xFF == 27:\n",
    "#         print(findNearestLine(df, 1186, 425))\n",
    "#         break\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9495d5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isLineInOtherLine(line, x_center_line, y_up_center_line, man_length):\n",
    "    x1, y1, x2, y2 = line\n",
    "    under_line = x2 - x1 if x2 > x1 else x1 - x2\n",
    "    small_under_line = x2 - x_center_line if y2 > y1 else x_center_line - x1\n",
    "    vertial_line = y1 - y2 if y1 > y2 else y2 - y1\n",
    "    y_lowest = y1 if y1 < y2 else y2\n",
    "    height = under_line * vertial_line / small_under_line\n",
    "    y_peresek_line = y_lowest + height - y_up_center_line\n",
    "    print(y_peresek_line, man_length)\n",
    "    return True if man_length > y_peresek_line else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5e6f2ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isManPeresekLine(df, x_center_line, y_up_center_line, i, man_length):\n",
    "    nearest_index = 0\n",
    "    lh_x, lh_y, rh_x, rh_y, ld_x, ld_y = df.iloc[i, 1], df.iloc[i, 2], df.iloc[i, 3], df.iloc[i, 4], df.iloc[i, 5], df.iloc[i, 6]\n",
    "    line1 = [lh_x, lh_y, rh_x, rh_y]\n",
    "    line2 = [ld_x, ld_y, lh_x, lh_y]\n",
    "    lines = [line1, line2]\n",
    "    for line in lines:\n",
    "        if line[0] < x_center_line < line[2]:\n",
    "            peresek = isLineInOtherLine(line, x_center_line, y_up_center_line, man_length)\n",
    "            if peresek == True:\n",
    "                return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "70878560",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')   # Suppress Matplotlib warnings\n",
    "\n",
    "def load_image_into_numpy_array(path):\n",
    "    \"\"\"Load an image from file into a numpy array.\n",
    "\n",
    "    Puts image into numpy array to feed into tensorflow graph.\n",
    "    Note that by convention we put it into a numpy array with shape\n",
    "    (height, width, channels), where channels=3 for RGB.\n",
    "\n",
    "    Args:\n",
    "      path: the file path to the image\n",
    "\n",
    "    Returns:\n",
    "      uint8 numpy array with shape (img_height, img_width, 3)\n",
    "    \"\"\"\n",
    "    return np.array(Image.open(path))\n",
    "\n",
    "\n",
    "video = cv2.VideoCapture(PATH_TO_VIDEO)\n",
    "while(video.isOpened()):\n",
    "    \n",
    "    ret, image_np = video.read()\n",
    "    \n",
    "    image_np = cv2.cvtColor(image_np, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    image_tensor = np.expand_dims(image_np, axis=0)\n",
    "    \n",
    "    \n",
    "    input_tensor = tf.convert_to_tensor(image_tensor)\n",
    "    \n",
    "    #------------------\n",
    "    detections = detect_fn(input_tensor)\n",
    "\n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy()\n",
    "                   for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "    #------------------\n",
    "    people = detect_people(input_tensor)\n",
    "    \n",
    "    num_detections = int(people.pop('num_detections'))\n",
    "    \n",
    "    people = {key: value[0, :num_detections].numpy()\n",
    "                   for key, value in people.items()}\n",
    "    people['num_detections'] = num_detections\n",
    "    \n",
    "    people['detection_classes'] = people['detection_classes'].astype(np.int64)\n",
    "\n",
    "    \n",
    "#     people_classes = np.array([])\n",
    "#     people_boxes = np.array([])\n",
    "#     people_scores = np.array([])\n",
    "    \n",
    "#     for i in range(0, len(people['detection_classes'])):\n",
    "#         if(people['detection_classes'][i] == 1):\n",
    "#             np.delete(people['detection_classes'], people['detection_classes'][i])\n",
    "#             np.delete(people['detection_boxes'], people['detection_boxes'][i])\n",
    "#             np.delete(people['detection_scores'], people['detection_scores'][i])\n",
    "    \n",
    "    #------------------\n",
    "    \n",
    "    image_np_with_detections = image_np.astype('uint8')\n",
    "    \n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "            image_np_with_detections,\n",
    "            detections['detection_boxes'],\n",
    "            detections['detection_classes'],\n",
    "            detections['detection_scores'],\n",
    "            category_index,\n",
    "            use_normalized_coordinates=True,\n",
    "            max_boxes_to_draw=4,\n",
    "            min_score_thresh=.40,\n",
    "            agnostic_mode=False)\n",
    "    \n",
    "#     viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "#             image_np_with_detections,\n",
    "#             people_boxes,\n",
    "#             people_classes,\n",
    "#             people_scores,\n",
    "#             category_index_people,\n",
    "#             use_normalized_coordinates=True,\n",
    "#             max_boxes_to_draw=4,\n",
    "#             min_score_thresh=.40,\n",
    "#             agnostic_mode=False)\n",
    "#     #---------------------------------\n",
    "    boxes = detections['detection_boxes']\n",
    "    max_boxes_to_draw = 4\n",
    "    scores = detections['detection_scores']\n",
    "    min_score_thresh=.40\n",
    "    \n",
    "    x_center = 0\n",
    "    y_center = 0\n",
    "    \n",
    "    for i in range(min(max_boxes_to_draw, boxes.shape[0])):\n",
    "        if scores is None or scores[i] > min_score_thresh:\n",
    "            ymax, xmin, ymin, xmax = boxes[i]\n",
    "            print(xmin, xmax, ymin, ymax)\n",
    "            im_height, im_width, _ = image_np_with_detections.shape\n",
    "\n",
    "            (x1, x2, y1, y2) = (xmin * im_width, xmax * im_width, ymin * im_height, ymax * im_height)\n",
    "\n",
    "            x_center = (x2 + x1) / 2\n",
    "            y_center = (y2 + y1) / 2\n",
    "            \n",
    "#             image_np_with_detections = cv2.rectangle(image_np_with_detections, (int(x1), int(y1)), (int(x2), int(y2)), (255, 0, 0), thickness = 3)\n",
    "    \n",
    "    boxes = people['detection_boxes']\n",
    "    scores = people['detection_scores']\n",
    "    \n",
    "    x_center = 0\n",
    "    y_center = 0\n",
    "    \n",
    "    dangerous_zone = findNearestLine(df_zone, x_center, y_center)\n",
    "    image_np_with_detections = zoneDrawer(df_zone, image_np_with_detections, dangerous_zone)\n",
    "    \n",
    "    for i in range(min(max_boxes_to_draw, boxes.shape[0])):\n",
    "        if scores is None or scores[i] > min_score_thresh:\n",
    "            if people['detection_classes'][i] == 1:\n",
    "                ymax, xmin, ymin, xmax = boxes[i]\n",
    "                print(xmin, xmax, ymin, ymax)\n",
    "                im_height, im_width, _ = image_np_with_detections.shape\n",
    "\n",
    "                (x1, x2, y1, y2) = (xmin * im_width, xmax * im_width, ymin * im_height, ymax * im_height)\n",
    "                \n",
    "                p_center = ((x1 + x2) / 2, y2)\n",
    "                \n",
    "                zone = df_zone.iloc[dangerous_zone]\n",
    "                man_length = y2 - y1 if y2 > y1 else y1 - y2\n",
    "                print('igreki', y1, y2, x1, x2)\n",
    "                if(isManPeresekLine(df_zone, x1, y2, dangerous_zone, man_length)):\n",
    "                    image_np_with_detections = cv2.rectangle(image_np_with_detections, (int(x1), int(y1)), (int(x2), int(y2)), (0, 0, 255), thickness = 3)\n",
    "                else:\n",
    "                    image_np_with_detections = cv2.rectangle(image_np_with_detections, (int(x1), int(y1)), (int(x2), int(y2)), (255, 0, 0), thickness = 3)\n",
    "                \n",
    "#                 if((p_center[1] < zone[2]) and (p_center[1] < zone[5]) and (p_center[1] > zone[6]) and (p_center[1] > zone[8])):\n",
    "#                     if((p_center[0] > zone[1]) and (p_center[0] < zone[3]) and (p_center[0] > zone[5]) and (p_center[0] < zone[7])):    \n",
    "#                         image_np_with_detections = cv2.rectangle(image_np_with_detections, (int(x1), int(y1)), (int(x2), int(y2)), (0, 0, 255), thickness = 3)\n",
    "#                     else:    \n",
    "#                         image_np_with_detections = cv2.rectangle(image_np_with_detections, (int(x1), int(y1)), (int(x2), int(y2)), (255, 0, 0), thickness = 3)\n",
    "#                 else:\n",
    "#                     image_np_with_detections = cv2.rectangle(image_np_with_detections, (int(x1), int(y1)), (int(x2), int(y2)), (255, 0, 0), thickness = 3)\n",
    "            \n",
    "              \n",
    "#             image_np_with_detections = cv2.rectangle(image_np_with_detections, (int(x1), int(y1)), (int(x2), int(y2)), (255, 0, 0), thickness = 3)\n",
    "#             cv2.circle(image_np_with_detections, (int(x_center), int(y_center)), 1, (255, 0, 0), thickness = 3)\n",
    "    \n",
    "#             class_name = category_index[output_dict['detection_classes'][i]]['name']\n",
    "#             print (\"This box is gonna get used\", boxes[i], output_dict['detection_classes'][i])\n",
    "    #---------------------------------\n",
    "    \n",
    "#     index_max_score = list(detections['detection_scores']).index(max(detections['detection_scores']))\n",
    "#     xmin, xmax, ymin, ymax = detections['detection_boxes'][index_max_score]\n",
    "#     im_height, im_width, _ = image_np_with_detections.shape\n",
    "    \n",
    "#     (x1, x2, y1, y2) = (xmin * im_width, xmax * im_width, ymin * im_height, ymax * im_height)\n",
    "    \n",
    "#     x_center = (x2 + x1) / 2\n",
    "#     y_center = (y2 + y1) / 2\n",
    "    \n",
    "#     image_np_with_detections = cv2.rectangle(image_np_with_detections, (int(x1), int(y1)), (int(x2), int(y2)), (255, 0, 0), thickness = 3)\n",
    "#     cv2.circle(image_np_with_detections, (int(x_center), int(y_center)), 1, (255, 0, 0), thickness = 3)\n",
    "    \n",
    "    cv2.imshow('Object detector', image_np_with_detections)\n",
    "\n",
    "    # Press 'q' to quit\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "# Clean up\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184d5d33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc38fb47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0187b2b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
